<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Parameter Inference · ProbNumDiffEq.jl</title><meta name="title" content="Parameter Inference · ProbNumDiffEq.jl"/><meta property="og:title" content="Parameter Inference · ProbNumDiffEq.jl"/><meta property="twitter:title" content="Parameter Inference · ProbNumDiffEq.jl"/><meta name="description" content="Documentation for ProbNumDiffEq.jl."/><meta property="og:description" content="Documentation for ProbNumDiffEq.jl."/><meta property="twitter:description" content="Documentation for ProbNumDiffEq.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">ProbNumDiffEq.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../dynamical_odes/">Second Order ODEs and Energy Preservation</a></li><li><a class="tocitem" href="../dae/">Differential Algebraic Equations</a></li><li><a class="tocitem" href="../exponential_integrators/">Probabilistic Exponential Integrators</a></li><li class="is-active"><a class="tocitem" href>Parameter Inference</a><ul class="internal"><li><a class="tocitem" href="#The-specific-problem,-in-code"><span>The specific problem, in code</span></a></li><li><a class="tocitem" href="#Computing-the-negative-log-likelihood"><span>Computing the negative log-likelihood</span></a></li><li><a class="tocitem" href="#Maximum-likelihood-parameter-inference"><span>Maximum-likelihood parameter inference</span></a></li><li><a class="tocitem" href="#API-Documentation"><span>API Documentation</span></a></li></ul></li></ul></li><li><span class="tocitem">Solvers and Options</span><ul><li><a class="tocitem" href="../../solvers/">Solvers</a></li><li><a class="tocitem" href="../../priors/">Priors</a></li><li><a class="tocitem" href="../../initialization/">Initialization</a></li><li><a class="tocitem" href="../../diffusions/">Diffusion models and calibration</a></li></ul></li><li><a class="tocitem" href="../../likelihoods/">Data Likelihoods</a></li><li><span class="tocitem">Benchmarks</span><ul><li><a class="tocitem" href="../../benchmarks/multi-language-wrappers/">Multi-Language Wrapper Benchmark</a></li><li><input class="collapse-toggle" id="menuitem-5-2" type="checkbox"/><label class="tocitem" for="menuitem-5-2"><span class="docs-label">Non-stiff ODEs</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../benchmarks/lotkavolterra/">Lotka-Volterra</a></li><li><a class="tocitem" href="../../benchmarks/hodgkinhuxley/">Hodgkin-Huxley</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5-3" type="checkbox"/><label class="tocitem" for="menuitem-5-3"><span class="docs-label">Stiff ODEs</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../benchmarks/vanderpol/">Van der Pol</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5-4" type="checkbox"/><label class="tocitem" for="menuitem-5-4"><span class="docs-label">Second-order ODEs</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../benchmarks/pleiades/">Pleiades</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5-5" type="checkbox"/><label class="tocitem" for="menuitem-5-5"><span class="docs-label">Differential-Algebraic Equations (DAEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../benchmarks/orego/">OREGO</a></li><li><a class="tocitem" href="../../benchmarks/rober/">ROBER</a></li></ul></li></ul></li><li><span class="tocitem">Internals</span><ul><li><a class="tocitem" href="../../filtering/">Filtering and Smoothing</a></li><li><a class="tocitem" href="../../implementation/">Implementation via OrdinaryDiffEq.jl</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Parameter Inference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Parameter Inference</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/nathanaelbosch/ProbNumDiffEq.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/nathanaelbosch/ProbNumDiffEq.jl/blob/main/docs/src/tutorials/ode_parameter_inference.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Parameter-Inference-with-ProbNumDiffEq.jl"><a class="docs-heading-anchor" href="#Parameter-Inference-with-ProbNumDiffEq.jl">Parameter Inference with ProbNumDiffEq.jl</a><a id="Parameter-Inference-with-ProbNumDiffEq.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Parameter-Inference-with-ProbNumDiffEq.jl" title="Permalink"></a></h1><p>Let&#39;s assume we have an initial value problem (IVP)</p><p class="math-container">\[\begin{aligned}
\dot{y} &amp;= f_\theta(y, t), \qquad y(t_0) = y_0,
\end{aligned}\]</p><p>which we observe through a set <span>$\mathcal{D} = \{u(t_n)\}_{n=1}^N$</span> of noisy data points</p><p class="math-container">\[\begin{aligned}
u(t_n) = H y(t_n) + v_n, \qquad v_n \sim \mathcal{N}(0, R).
\end{aligned}\]</p><p>The question of interest is: How can we compute the marginal likelihood <span>$p(\mathcal{D} \mid \theta)$</span>? Short answer: We can&#39;t. It&#39;s intractable, because computing the true IVP solution exactly <span>$y(t)$</span> is intractable. What we can do however is compute an approximate marginal likelihood. This is what <code>ProbNumDiffEq.DataLikelihoods</code> provides.</p><h2 id="The-specific-problem,-in-code"><a class="docs-heading-anchor" href="#The-specific-problem,-in-code">The specific problem, in code</a><a id="The-specific-problem,-in-code-1"></a><a class="docs-heading-anchor-permalink" href="#The-specific-problem,-in-code" title="Permalink"></a></h2><p>Let&#39;s assume that the true underlying dynamics are given by a FitzHugh-Nagumo model</p><pre><code class="language-julia hljs">using ProbNumDiffEq, LinearAlgebra, OrdinaryDiffEq, Plots
Plots.theme(:default; markersize=2, markerstrokewidth=0.1)

function f(du, u, p, t)
    a, b, c = p
    du[1] = c*(u[1] - u[1]^3/3 + u[2])
    du[2] = -(1/c)*(u[1] -  a - b*u[2])
end
u0 = [-1.0, 1.0]
tspan = (0.0, 20.0)
p = (0.2, 0.2, 3.0)
true_prob = ODEProblem(f, u0, tspan, p)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr38_2" style="color:#56b6c2">ODEProblem</span> with uType <span class="sgr38_2" style="color:#56b6c2">Vector{Float64}</span> and tType <span class="sgr38_2" style="color:#56b6c2">Float64</span>. In-place: <span class="sgr38_2" style="color:#56b6c2">true</span>
timespan: (0.0, 20.0)
u0: 2-element Vector{Float64}:
 -1.0
  1.0</code></pre><p>from which we generate some artificial noisy data</p><pre><code class="language-julia hljs">true_sol = solve(true_prob, Vern9(), abstol=1e-10, reltol=1e-10)

times = 1:0.5:20
σ = 1e-1
H = [1 0;]
odedata = [H*true_sol(t) .+ σ * randn() for t in times]

plot(true_sol, color=:black, linestyle=:dash, label=[&quot;True Solution&quot; &quot;&quot;])
scatter!(times, stack(odedata)&#39;,  color=1, label=[&quot;Noisy Data&quot; &quot;&quot;])</code></pre><img src="6815a5ef.svg" alt="Example block output"/><p>Our goal is then to recover the true parameter <code>p</code> (and thus also the true trajectory plotted above) the noisy data.</p><h2 id="Computing-the-negative-log-likelihood"><a class="docs-heading-anchor" href="#Computing-the-negative-log-likelihood">Computing the negative log-likelihood</a><a id="Computing-the-negative-log-likelihood-1"></a><a class="docs-heading-anchor-permalink" href="#Computing-the-negative-log-likelihood" title="Permalink"></a></h2><p>To do parameter inference - be it maximum-likelihod, maximum a posteriori, or full Bayesian inference with MCMC - we need to evaluate the likelihood of given a parameter estimate <span>$\theta_\text{est}$</span>, which corresponds to the probability of the data under the trajectory returned by the ODE solver</p><pre><code class="language-julia hljs">θ_est = (0.1, 0.1, 2.0)
prob = remake(true_prob, p=θ_est)
plot(true_sol, color=:black, linestyle=:dash, label=[&quot;True Solution&quot; &quot;&quot;])
scatter!(times, stack(odedata)&#39;, color=1, label=[&quot;Noisy Data&quot; &quot;&quot;])
sol = solve(prob, EK1(), adaptive=false, dt=1e-1)
plot!(sol, color=2, label=[&quot;Numerical solution for θ_est&quot; &quot;&quot;])</code></pre><img src="41f63bbb.svg" alt="Example block output"/><p>This quantity can be computed in multiple ways; see  <a href="../../likelihoods/#Data-Likelihoods">Data Likelihoods</a>. Here we use  <a href="../../likelihoods/#ProbNumDiffEq.fenrir_data_loglik"><code>ProbNumDiffEq.DataLikelihoods.fenrir_data_loglik</code></a>:</p><pre><code class="language-julia hljs">using ProbNumDiffEq.DataLikelihoods

data = (t=times, u=odedata)
nll = -fenrir_data_loglik(
    prob, EK1(smooth=true);
    data, observation_noise_cov=σ^2, observation_matrix=H,
    adaptive=false, dt=1e-1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">6493.781566927634</code></pre><p>This is the negative marginal log-likelihood of the parameter <code>θ_est</code>. You can use it as any other NLL: Optimize it to compute maximum-likelihood estimates or MAPs, or plug it into MCMC to sample from the posterior. In our paper [<a href="../../references/#tronarp22fenrir">3</a>] we compute MLEs by pairing Fenrir with <a href="http://optimization.sciml.ai/stable/">Optimization.jl</a> and <a href="https://juliadiff.org/ForwardDiff.jl/stable/">ForwardDiff.jl</a>. Let&#39;s quickly explore how to do this next.</p><h2 id="Maximum-likelihood-parameter-inference"><a class="docs-heading-anchor" href="#Maximum-likelihood-parameter-inference">Maximum-likelihood parameter inference</a><a id="Maximum-likelihood-parameter-inference-1"></a><a class="docs-heading-anchor-permalink" href="#Maximum-likelihood-parameter-inference" title="Permalink"></a></h2><p>To compute a maximum-likelihood estimate (MLE), we just need to maximize <span>$\theta \to p(\mathcal{D} \mid \theta)$</span> - that is, minimize the <code>nll</code> from above. We use <a href="https://docs.sciml.ai/Optimization/stable/">Optimization.jl</a> for this. First, define a loss function and create an <code>OptimizationProblem</code></p><pre><code class="language-julia hljs">using Optimization, OptimizationOptimJL

function loss(x, _)
    ode_params = x[begin:end-1]
    prob = remake(true_prob, p=ode_params)
    κ² = exp(x[end]) # we also optimize the diffusion parameter of the EK1
    return -fenrir_data_loglik(
        prob, EK1(smooth=true, diffusionmodel=FixedDiffusion(κ², false));
        data, observation_noise_cov=σ^2, observation_matrix=H,
        adaptive=false, dt=1e-1
    )
end

fun = OptimizationFunction(loss, Optimization.AutoForwardDiff())
optprob = OptimizationProblem(
    fun, [θ_est..., 1e0];
    lb=[0.0, 0.0, 0.0, -10], ub=[1.0, 1.0, 5.0, 20] # lower and upper bounds
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr38_2" style="color:#56b6c2">OptimizationProblem</span>. In-place: <span class="sgr38_2" style="color:#56b6c2">true</span>
u0: 4-element Vector{Float64}:
 0.1
 0.1
 2.0
 1.0</code></pre><p>Then, just <code>solve</code> it! Here we use LBFGS:</p><pre><code class="language-julia hljs">optsol = solve(optprob, LBFGS())
p_mle = optsol.u[1:3]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Float64}:
 0.20115726528627073
 0.1999877191927223
 3.00588240198558</code></pre><p>Success! The computed MLE is quite close to the true parameter which we used to generate the data. As a final step, let&#39;s plot the true solution, the data, and the result of the MLE:</p><pre><code class="language-julia hljs">plot(true_sol, color=:black, linestyle=:dash, label=[&quot;True Solution&quot; &quot;&quot;])
scatter!(times, stack(odedata)&#39;, color=1, label=[&quot;Noisy Data&quot; &quot;&quot;])
mle_sol = solve(remake(true_prob, p=p_mle), EK1())
plot!(mle_sol, color=3, label=[&quot;MLE-parameter Solution&quot; &quot;&quot;])</code></pre><img src="c8f7f05b.svg" alt="Example block output"/><p>Looks good!</p><h2 id="API-Documentation"><a class="docs-heading-anchor" href="#API-Documentation">API Documentation</a><a id="API-Documentation-1"></a><a class="docs-heading-anchor-permalink" href="#API-Documentation" title="Permalink"></a></h2><p>For more details, see the API documentation of <code>ProbNumDiffEq.DataLikelihoods</code> at <a href="../../likelihoods/#Data-Likelihoods">Data Likelihoods</a>.</p><h3 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h3><div class="citation noncanonical"><dl><dt>[3]</dt><dd><div>F. Tronarp, N. Bosch and P. Hennig. <a href="https://proceedings.mlr.press/v162/tronarp22a.html"><em>Fenrir: Physics-Enhanced Regression for Initial Value                   Problems</em></a>. In: <em>Proceedings of the 39th International Conference on Machine                   Learning</em>, Vol. 162 of <em>Proceedings of Machine Learning Research</em>, edited by K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu and S. Sabato (PMLR, 17–23 Jul 2022); pp. 21776–21794.</div></dd><dt>[10]</dt><dd><div>M. Wu and M. Lysy. <a href="http://arxiv.org/abs/2306.05566"><em>Data-Adaptive Probabilistic Likelihood Approximation for                   Ordinary Differential Equations</em></a>. CoRR (2023), <a href="https://arxiv.org/abs/2306.05566">arXiv:2306.05566 [stat.ML]</a>.</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../exponential_integrators/">« Probabilistic Exponential Integrators</a><a class="docs-footer-nextpage" href="../../solvers/">Solvers »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Monday 26 February 2024 08:54">Monday 26 February 2024</span>. Using Julia version 1.10.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
